## 背景

現在、大学院の授業の一環で個人プロジェクトとして、iPad上でApple Pencilを使って書いたメモ書きなどをマークダウンの形式でexportできるアプリを作ろうとしています(半分くらい趣味でやっているという側面もあります)。

一旦はAppleが提供しているText Detection / RecognitionのAPI(VNRecognizeText)を利用してメモ中に書かれたテキストを認識させるという方向で進めていたのですが、以下の2点が課題として出てきたので自前でモデルを学習させようとしています。

1. VNRecognizeTextの認識精度はやや不十分なことがある
2. ゆくゆくはテキストだけではなく、イラストや数式なども扱いたいと考えており、その場合はイラスト領域のdetectionや数式領域のdetectionをしたいと考えている

## 質問

質問させていただきたいのは以下の三点です。

1. iPad上でのテキストの位置を出来るだけ正確に把握しておきたい(認識されたテキストの位置関係が文意の読み取りに影響するのではないかと考えているため)ので、iPadの画面をそのままのサイズで画像化して文字領域を予測したいと考えているが、この方針で良いか意見を伺いたいです。かなりざっくりした質問ですみません。

2. イラスト領域の検出、数式領域の検出も、text detectionと同じ方針でできるのではないかと考えており、agatanさんの資料のPixelLinkのモデルの出力部のチャネルを増やして、Multi Task学習のようにしようと考えているのですが、この方針に関しても意見を伺いたいです。これもまたざっくりした質問ですみません。

3. 手書きの線画のイラストをまとめたデータセットなどをご存知でしたら教えていただけるとありがたいです。


その他、アプリ全体の構想や方針などについての意見も忌憚なくご意見いただければとてもありがたいです！  
不躾な質問で申し訳ありませんが、よろしくお願いします！

